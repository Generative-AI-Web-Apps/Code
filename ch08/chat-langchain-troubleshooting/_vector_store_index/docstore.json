[["0",{"pageContent":"JSS\nJournal of Statistical Software\nAugust 2014, Volume 59, Issue 10.http://www.jstatsoft.org/\nTidy Data\nHadley Wickham\nRStudio\nAbstract\nA huge amount of effort is spent cleaning data to get it ready for analysis, but there\nhas been little research on how to make data cleaning as easy and effective as possible.\nThis  paper  tackles  a  small,  but  important,  component  of  data  cleaning:  data  tidying.\nTidy datasets are easy to manipulate, model and visualize, and have a specific structure:\neach variable is a column, each observation is a row, and each type of observational unit\nis  a  table.   This  framework  makes  it  easy  to  tidy  messy  datasets  because  only  a  small\nset  of  tools  are  needed  to  deal  with  a  wide  range  of  un-tidy  datasets.   This  structure\nalso  makes  it  easier  to  develop  tidy  tools  for  data  analysis,  tools  that  both  input  and\noutput tidy datasets.  The advantages of a consistent data structure and matching tools\nare demonstrated with a case study free from mundane data manipulation chores.\nKeywords: data cleaning, data tidying, relational databases,R.\n1.  Introduction\nIt is often said that 80% of data analysis is spent on the process of cleaning and preparing\nthe data (Dasu and Johnson 2003).  Data preparation is not just a first step,  but must be\nrepeated many times over the course of analysis as new problems come to light or new data","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":1,"lines":{"from":1,"to":22}}}}],["1",{"pageContent":"the data (Dasu and Johnson 2003).  Data preparation is not just a first step,  but must be\nrepeated many times over the course of analysis as new problems come to light or new data\nis collected.  Despite the amount of time it takes, there has been surprisingly little research\non how to clean data well.  Part of the challenge is the breadth of activities it encompasses:\nfrom outlier checking, to date parsing, to missing value imputation.  To get a handle on the\nproblem, this paper focuses on a small, but important, aspect of data cleaning that I call data\ntidying:  structuring datasets to facilitate analysis.\nThe principles of tidy data provide a standard way to organize data values within a dataset.\nA standard makes initial data cleaning easier because you do not need to start from scratch\nand reinvent the wheel every time.  The tidy data standard has been designed to facilitate\ninitial exploration and analysis of the data, and to simplify the development of data analysis\ntools that work well together.  Current tools often require translation.  You have to spend time","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":1,"lines":{"from":21,"to":32}}}}],["2",{"pageContent":"2Tidy Data\nmunging the output from one tool so you can input it into another.  Tidy datasets and tidy\ntools work hand in hand to make data analysis easier, allowing you to focus on the interesting\ndomain problem, not on the uninteresting logistics of data.\nThe principles of tidy data are closely tied to those of relational databases and Codd’s rela-\ntional algebra (Codd 1990), but are framed in a language familiar to statisticians.  Computer\nscientists  have  also  contributed  much  to  the  study  of  data  cleaning.   For  example,  Laksh-\nmanan, Sadri, and Subramanian (1996) define an extension toSQLto allow it to operate on\nmessy datasets, Raman and Hellerstein (2001) provide a framework for cleaning datasets, and\nKandel, Paepcke, Hellerstein, and Heer (2011) develop an interactive tool with a friendly user\ninterface which automatically creates code to clean data.  These tools are useful but they are\npresented in a language foreign to most statisticians, they fail to give much advice on how\ndatasets should be structured, and they lack connections to the tools of data analysis.\nThe  development  of  tidy  data  has  been  driven  by  my  experience  from  working  with  real-\nworld datasets.  With few, if any, constraints on their organization, such datasets are often\nconstructed  in  bizarre  ways.   I  have  spent  countless  hours  struggling  to  get  such  datasets\norganized in a way that makes data analysis possible, let alone easy.  I have also struggled","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":2,"lines":{"from":1,"to":17}}}}],["3",{"pageContent":"constructed  in  bizarre  ways.   I  have  spent  countless  hours  struggling  to  get  such  datasets\norganized in a way that makes data analysis possible, let alone easy.  I have also struggled\nto impart these skills to my students so they could tackle real-world datasets on their own.\nIn the course of these struggles I developed thereshapeandreshape2(Wickham 2007) pack-\nages.  While I could intuitively use the tools and teach them through examples, I lacked the\nframework to make my intuition explicit.  This paper provides that framework.  It provides a\ncomprehensive “philosophy of data”:  one that underlies my work in theplyr(Wickham 2011)\nandggplot2(Wickham 2009) packages.\nThe  paper  proceeds  as  follows.   Section  2  begins  by  defining  the  three  characteristics  that\nmake  a  dataset  tidy.   Since  most  real  world  datasets  are  not  tidy,  Section  3  describes  the\noperations needed to make messy datasets tidy, and illustrates the techniques with a range\nof  real  examples.   Section  4  defines  tidy  tools,  tools  that  input  and  output  tidy  datasets,\nand discusses how tidy data and tidy tools together can make data analysis easier.  These\nprinciples are illustrated with a small case study in Section 5.  Section 6 concludes with a\ndiscussion  of  what  this  framework  misses  and  what  other  approaches  might  be  fruitful  to\npursue.\n2.  Defining tidy data\nHappy families are all alike; every\nunhappy family is unhappy in its own\nway.\nLeo Tolstoy","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":2,"lines":{"from":16,"to":36}}}}],["4",{"pageContent":"pursue.\n2.  Defining tidy data\nHappy families are all alike; every\nunhappy family is unhappy in its own\nway.\nLeo Tolstoy\nLike families, tidy datasets are all alike but every messy dataset is messy in its own way.  Tidy\ndatasets provide a standardized way to link the structure of a dataset (its physical layout)\nwith its semantics (its meaning).  In this section, I will provide some standard vocabulary for\ndescribing the structure and semantics of a dataset, and then use those definitions to define\ntidy data.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":2,"lines":{"from":31,"to":41}}}}],["5",{"pageContent":"Journal of Statistical Software3\ntreatmenta    treatmentb\nJohn Smith—2\nJane Doe1611\nMary Johnson31\nTable 1:  Typical presentation dataset.\nJohn Smith    Jane Doe    Mary Johnson\ntreatmenta—163\ntreatmentb2111\nTable 2:  The same data as in Table 1 but structured differently.\n2.1.  Data structure\nMost statistical datasets are rectangular tables made up ofrowsandcolumns.  The columns\nare almost always labeled and the rows are sometimes labeled.  Table 1 provides some data\nabout an imaginary experiment in a format commonly seen in the wild.  The table has two\ncolumns and three rows, and both rows and columns are labeled.\nThere are many ways to structure the same underlying data.  Table 2 shows the same data\nas Table 1, but the rows and columns have been transposed.  The data is the same, but the\nlayout is different.  Our vocabulary of rows and columns is simply not rich enough to describe\nwhy the two tables represent the same data.  In addition to appearance, we need a way to\ndescribe the underlying semantics, or meaning, of the values displayed in tables.\n2.2.  Data semantics\nA  dataset  is  a  collection  ofvalues,  usually  either  numbers  (if  quantitative)  or  strings  (if\nqualitative).   Values  are  organized  in  two  ways.   Every  value  belongs  to  avariableand  an\nobservation.  A variable contains all values that measure the same underlying attribute (like\nheight, temperature, duration) across units.  An observation contains all values measured on","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":3,"lines":{"from":1,"to":25}}}}],["6",{"pageContent":"observation.  A variable contains all values that measure the same underlying attribute (like\nheight, temperature, duration) across units.  An observation contains all values measured on\nthe same unit (like a person, or a day, or a race) across attributes.\nTable 3 reorganizes Table 1 to make the values, variables and observations more clear.  The\ndataset contains 18 values representing three variables and six observations.  The variables\nare:\n1.person, with three possible values (John Smith, Mary Johnson, and Jane Doe).\n2.treatment, with two possible values (a and b).\n3.result, with five or six values depending on how you think of the missing value (—,\n16, 3, 2, 11, 1).\nThe experimental design tells us more about the structure of the observations.  In this ex-\nperiment, every combination ofpersonandtreatmentwas measured, a completely crossed\ndesign.  The experimental design also determines whether or not missing values can be safely\ndropped.  In this experiment, the missing value represents an observation that should have","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":3,"lines":{"from":24,"to":37}}}}],["7",{"pageContent":"4Tidy Data\npersontreatment    result\nJohn Smitha—\nJane Doea16\nMary Johnson    a3\nJohn Smithb2\nJane Doeb11\nMary Johnson    b1\nTable 3:  The same data as in Table 1 but with variables in columns and observations in rows.\nbeen made, but was not, so it is important to keep it.  Structural missing values, which rep-\nresent measurements that cannot be made (e.g., the count of pregnant males) can be safely\nremoved.\nFor a given dataset, it is usually easy to figure out what are observations and what are vari-\nables, but it is surprisingly difficult to precisely define variables and observations in general.\nFor example, if the columns in the Table 1 wereheightandweightwe would have been happy\nto call them variables.  If the columns wereheightandwidth, it would be less clear cut, as\nwe might think of height and width as values of adimensionvariable.  If the columns were\nhome phoneandwork phone, we could treat these as two variables, but in a fraud detection\nenvironment we might want variablesphone numberandnumber typebecause the use of one\nphone number for multiple people might suggest fraud.  A general rule of thumb is that it is\neasier to describe functional relationships between variables (e.g.,zis a linear combination\nofxandy,densityis the ratio ofweighttovolume) than between rows,  and it is easier\nto make comparisons between groups of observations (e.g., average of group a vs. average of\ngroup b) than between groups of columns.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":4,"lines":{"from":1,"to":24}}}}],["8",{"pageContent":"to make comparisons between groups of observations (e.g., average of group a vs. average of\ngroup b) than between groups of columns.\nIn a given analysis, there may be multiple levels of observations.  For example, in a trial of new\nallergy medication we might have three observational types:  demographic data collected from\neach person (age,sex,race), medical data collected from each person on each day (number of\nsneezes,redness of eyes), and meteorological data collected on each day (temperature,\npollen count).\n2.3.  Tidy data\nTidy data is a standard way of mapping the meaning of a dataset to its structure.  A dataset is\nmessy or tidy depending on how rows, columns and tables are matched up with observations,\nvariables and types.  Intidy data:\n1.  Each variable forms a column.\n2.  Each observation forms a row.\n3.  Each type of observational unit forms a table.\nThis is Codd’s 3rd normal form (Codd 1990), but with the constraints framed in statistical\nlanguage,  and  the  focus  put  on  a  single  dataset  rather  than  the  many  connected  datasets\ncommon in relational databases.Messy datais any other arrangement of the data.\nTable 3 is the tidy version of Table 1.  Each row represents an observation, theresultof one\ntreatmenton oneperson, and each column is a variable.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":4,"lines":{"from":23,"to":41}}}}],["9",{"pageContent":"Journal of Statistical Software5\nTidy data makes it easy for an analyst or a computer to extract needed variables because it\nprovides a standard way of structuring a dataset.  Compare Table 3 to Table 1:  in Table 1\nyou  need  to  use  different  strategies  to  extract  different  variables.   This  slows  analysis  and\ninvites errors.  If you consider how many data analysis operations involve all of the values in a\nvariable (every aggregation function), you can see how important it is to extract these values\nin a simple, standard way.  Tidy data is particularly well suited for vectorized programming\nlanguages  likeR(RCore  Team  2014),  because  the  layout  ensures  that  values  of  different\nvariables from the same observation are always paired.\nWhile the order of variables and observations does not affect analysis, a good ordering makes\nit easier to scan the raw values.  One way of organizing variables is by their role in the analysis:\nare values fixed by the design of the data collection, or are they measured during the course of\nthe experiment?  Fixed variables describe the experimental design and are known in advance.\nComputer scientists often call fixed variables dimensions, and statisticians usually denote them\nwith subscripts on random variables.  Measured variables are what we actually measure in the\nstudy.  Fixed variables should come first, followed by measured variables, each ordered so that","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":5,"lines":{"from":1,"to":16}}}}],["10",{"pageContent":"with subscripts on random variables.  Measured variables are what we actually measure in the\nstudy.  Fixed variables should come first, followed by measured variables, each ordered so that\nrelated variables are contiguous.  Rows can then be ordered by the first variable,  breaking\nties with the second and subsequent (fixed) variables.  This is the convention adopted by all\ntabular displays in this paper.\n3.  Tidying messy datasets\nReal datasets can, and often do, violate the three precepts of tidy data in almost every way\nimaginable. While occasionally you do get a dataset that you can start analyzing immediately,\nthis is the exception,  not the rule.  This section describes the five most common problems\nwith messy datasets, along with their remedies:\nColumn headers are values, not variable names.\nMultiple variables are stored in one column.\nVariables are stored in both rows and columns.\nMultiple types of observational units are stored in the same table.\nA single observational unit is stored in multiple tables.\nSurprisingly, most messy datasets, including types of messiness not explicitly described above,\ncan be tidied with a small set of tools:  melting, string splitting, and casting.  The following\nsections illustrate each problem with a real dataset that I have encountered, and show how\nto tidy them.  The complete datasets and theRcode used to tidy them are available online\nathttps://github.com/hadley/tidy-data, and in the online supplementary materials for","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":5,"lines":{"from":15,"to":34}}}}],["11",{"pageContent":"to tidy them.  The complete datasets and theRcode used to tidy them are available online\nathttps://github.com/hadley/tidy-data, and in the online supplementary materials for\nthis paper.\n3.1.  Column headers are values, not variable names\nA common type of messy dataset is tabular data designed for presentation, where variables\nform both the rows and columns, and column headers are values, not variable names.  While","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":5,"lines":{"from":33,"to":38}}}}],["12",{"pageContent":"6Tidy Data\nreligion<$10k    $10–20k    $20–30k    $30–40k    $40–50k    $50–75k\nAgnostic2734608176137\nAtheist122737523570\nBuddhist272130343358\nCatholic4186177326706381116\nDon’t know/refused151415111035\nEvangelical Prot57586910649828811486\nHindu19791134\nHistorically Black Prot228244236238197223\nJehovah’s Witness202724242130\nJewish191925253095\nTable  4:  The  first  ten  rows  of  data  on  income  and  religion  from  the  Pew  Forum.   Three\ncolumns, $75–100k, $100–150k and>150k, have been omitted.\nrow    a    bc\nA14    7\nB25    8\nC36    9\n(a) Raw data\nrow    column    value\nAa1\nBa2\nCa3\nAb4\nBb5\nCb6\nAc7\nBc8\nCc9\n(b) Molten data\nTable 5:  A simple example of melting.  (a) is melted with one colvar, row, yielding the molten\ndataset (b).  The information in each table is exactly the same, just stored in a different way.\nI would call this arrangement messy,  in some cases it can be extremely useful.  It provides\nefficient storage for completely crossed designs, and it can lead to extremely efficient compu-\ntation if desired operations can be expressed as matrix operations.  This issue is discussed in\ndepth in Section 6.\nTable 4 shows a subset of a typical dataset of this form.  This dataset explores the relationship\nbetween income and religion in the US. It comes from a report\n1\nproduced by the Pew Research\nCenter, an American think-tank that collects data on attitudes to topics ranging from religion\nto the internet, and produces many reports that contain datasets in this format.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":6,"lines":{"from":1,"to":42}}}}],["13",{"pageContent":"Center, an American think-tank that collects data on attitudes to topics ranging from religion\nto the internet, and produces many reports that contain datasets in this format.\nThis dataset has three variables,religion,incomeandfrequency.  To tidy it, we need to\nmelt,  or  stack  it.   In  other  words,  we  need  to  turn  columns  into  rows.   While  this  is  often\ndescribed  as  making  wide  datasets  long  or  tall,  I  will  avoid  those  terms  because  they  are\nimprecise.  Melting is parameterized by a list of columns that are already variables, orcolvars\nfor short.  The other columns are converted into two variables:  a new variable calledcolumn\n1\nhttp://religions.pewforum.org/pdf/comparison-Income%20Distribution%20of%20Religious%\n20Traditions.pdf","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":6,"lines":{"from":41,"to":50}}}}],["14",{"pageContent":"Journal of Statistical Software7\nreligionincomefreq\nAgnostic<$10k27\nAgnostic    $10–20k34\nAgnostic    $20–30k60\nAgnostic    $30–40k81\nAgnostic    $40–50k76\nAgnostic    $50–75k137\nAgnostic    $75–100k122\nAgnostic    $100–150k109\nAgnostic>150k84\nAgnostic    Don’t know/refused96\nTable 6:  The first ten rows of the tidied Pew survey dataset on income and religion.  The\ncolumnhas been renamed toincome, andvaluetofreq.\nyear    artisttracktime    date.entered    wk1    wk2    wk3\n2000    2 PacBaby Don’t Cry4:222000-02-26878272\n2000    2Ge+herThe Hardest Part Of ...3:152000-09-02918792\n2000    3 Doors DownKryptonite3:532000-04-08817068\n2000    98^0Give Me Just One Nig...    3:242000-08-19513934\n2000    A*TeensDancing Queen3:442000-07-08979796\n2000    AaliyahI Don’t Wanna4:152000-01-29846251\n2000    AaliyahTry Again4:032000-03-18595338\n2000    Adams, Yolanda    Open My Heart5:302000-08-26767674\nTable 7:  The first eight Billboard top hits for 2000.  Other columns not shown arewk4,wk5,\n...,wk75.\nthat contains repeated column headings and a new variable calledvaluethat contains the\nconcatenated data values from the previously separate columns.  This is illustrated in Table 5\nwith a toy dataset.  The result of melting is amoltendataset.\nThe  Pew  dataset  has  one  colvar,religion,  and  melting  yields  Table  6.   To  better  reflect\ntheir roles in this dataset, thevariablecolumn has been renamed toincome, and thevalue","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":7,"lines":{"from":1,"to":30}}}}],["15",{"pageContent":"The  Pew  dataset  has  one  colvar,religion,  and  melting  yields  Table  6.   To  better  reflect\ntheir roles in this dataset, thevariablecolumn has been renamed toincome, and thevalue\ncolumn tofreq.  This form is tidy because each column represents a variable and each row\nrepresents an observation, in this case a demographic unit corresponding to a combination of\nreligionandincome.\nAnother common use of this data format is to record regularly spaced observations over time.\nFor example, the Billboard dataset shown in Table 7 records the date a song first entered the\nBillboard Top 100.  It has variables forartist,track,date.entered,rankandweek.  The\nrank in each week after it enters the top 100 is recorded in 75 columns,wk1towk75.  If a song\nis in the Top 100 for less than 75 weeks the remaining columns are filled with missing values.\nThis form of storage is not tidy, but it is useful for data entry.  It reduces duplication since\notherwise each song in each week would need its own row, and song metadata like title and\nartist would need to be repeated.  This issue will be discussed in more depth in Section 3.4.\nThis  dataset  has  colvarsyear,artist,track,time,  anddate.entered.   Melting  yields\nTable 8.  I have also done a little cleaning as well as tidying:columnhas been converted to","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":7,"lines":{"from":29,"to":43}}}}],["16",{"pageContent":"8Tidy Data\nyear    artisttime    trackdateweek    rank\n2000    2 Pac4:22Baby Don’t Cry2000-02-26187\n2000    2 Pac4:22Baby Don’t Cry2000-03-04282\n2000    2 Pac4:22Baby Don’t Cry2000-03-11372\n2000    2 Pac4:22Baby Don’t Cry2000-03-18477\n2000    2 Pac4:22Baby Don’t Cry2000-03-25587\n2000    2 Pac4:22Baby Don’t Cry2000-04-01694\n2000    2 Pac4:22Baby Don’t Cry2000-04-08799\n2000    2Ge+her3:15The Hardest Part Of ...    2000-09-02191\n2000    2Ge+her3:15The Hardest Part Of ...    2000-09-09287\n2000    2Ge+her3:15The Hardest Part Of ...    2000-09-16392\n2000    3 Doors Down    3:53Kryptonite2000-04-08181\n2000    3 Doors Down    3:53Kryptonite2000-04-15270\n2000    3 Doors Down    3:53Kryptonite2000-04-22368\n2000    3 Doors Down    3:53Kryptonite2000-04-29467\n2000    3 Doors Down    3:53Kryptonite2000-05-06566\nTable 8:  First fifteen rows of the tidied Billboard dataset.  Thedatecolumn does not appear\nin the original table, but can be computed fromdate.enteredandweek.\ncountryyear    m014    m1524    m2534    m3544    m4554    m5564    m65    mu    f014\nAD20000010000——\nAE2000244651210—3\nAF2000522281831491299480—93\nAG20000000001—1\nAL20002192114241916—3\nAM20002152130131632621—1\nAN20000012000—0\nAO20001869991003912482312194—247\nAR200097278594402419368330—121\nAS2000————11———\nTable 9:  Original TB dataset.  Corresponding to each ‘m’ column for males, there is also an\n‘f’ column for females,f1524,f2534and so on.  These are not shown to conserve space.  Note","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":8,"lines":{"from":1,"to":32}}}}],["17",{"pageContent":"AS2000————11———\nTable 9:  Original TB dataset.  Corresponding to each ‘m’ column for males, there is also an\n‘f’ column for females,f1524,f2534and so on.  These are not shown to conserve space.  Note\nthe mixture of 0s and missing values (—).  This is due to the data collection process and the\ndistinction is important for this dataset.\nweekby extracting the number, anddatehas been computed fromdate.enteredandweek.\n3.2.  Multiple variables stored in one column\nAfter melting, thecolumnvariable names often becomes a combination of multiple underlying\nvariable  names.   This is illustrated  by the  tuberculosis  (TB) dataset,  a  sample  of  which is\nshown  in  Table  9.   This  dataset  comes  from  the  World  Health  Organization,  and  records\nthe counts of confirmed tuberculosis cases bycountry,year, and demographic group.  The\ndemographic  groups  are  broken  down  bysex(m,  f)  andage(0–14,  15–25,  25–34,  35–44,\n45–54, 55–64, unknown).","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":8,"lines":{"from":30,"to":42}}}}],["18",{"pageContent":"Journal of Statistical Software9\ncountryyear    column    cases\nAD2000    m0140\nAD2000    m15240\nAD2000    m25341\nAD2000    m35440\nAD2000    m45540\nAD2000    m55640\nAD2000    m650\nAE2000    m0142\nAE2000    m15244\nAE2000    m25344\nAE2000    m35446\nAE2000    m45545\nAE2000    m556412\nAE2000    m6510\nAE2000    f0143\n(a) Molten data\ncountryyear    sex    agecases\nAD2000    m0–140\nAD2000    m15–240\nAD2000    m25–341\nAD2000    m35–440\nAD2000    m45–540\nAD2000    m55–640\nAD2000    m65+0\nAE2000    m0–142\nAE2000    m15–244\nAE2000    m25–344\nAE2000    m35–446\nAE2000    m45–545\nAE2000    m55–6412\nAE2000    m65+10\nAE2000    f0-143\n(b) Tidy data\nTable 10: Tidying the TB dataset requires first melting, and then splitting thecolumncolumn\ninto two variables:sexandage.\nColumn headers in this format are often separated by some character (.,-,_,:).  While the\nstring can be broken into pieces using that character as a divider, in other cases, such as for\nthis dataset, more careful string processing is required.  For example, the variable names can\nbe matched to a lookup table that converts single compound value into multiple component\nvalues.\nTable 10(a) shows the results of melting the TB dataset, and Table 10(b) shows the results\nof splitting the single columncolumninto two real variables:ageandsex.\nStoring the values in this form resolves another problem in the original data.  We want to\ncompare rates, not counts.  But to compute rates, we need to know the population.  In the","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":9,"lines":{"from":1,"to":46}}}}],["19",{"pageContent":"Storing the values in this form resolves another problem in the original data.  We want to\ncompare rates, not counts.  But to compute rates, we need to know the population.  In the\noriginal format, there is no easy way to add a population variable.  It has to be stored in a\nseparate table, which makes it hard to correctly match populations to counts.  In tidy form,\nadding variables for population and rate is easy.  They are just additional columns.\n3.3.  Variables are stored in both rows and columns\nThe most complicated form of messy data occurs when variables are stored in both rows and\ncolumns.  Table 11 shows daily weather data from the Global Historical Climatology Network\nfor  one  weather  station  (MX17004)  in  Mexico  for  five  months  in  2010.   It  has  variables  in\nindividual columns (id,year,month), spread across columns (day, d1–d31) and across rows\n(tmin,tmax) (minimum and maximum temperature).  Months with less than 31 days have\nstructural  missing  values  for  the  last  day(s)  of  the  month.   Theelementcolumn  is  not  a\nvariable; it stores the names of variables.\nTo tidy this dataset we first melt it with colvarsid,year,monthand the column that contains\nvariable names,element.  This yields Table 12(a).  For presentation,  we have dropped the","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":9,"lines":{"from":45,"to":59}}}}],["20",{"pageContent":"10Tidy Data\nidyear    month    element    d1d2d3    d4d5    d6    d7    d8\nMX17004    20101    tmax————————\nMX17004    20101    tmin————————\nMX17004    20102    tmax—    27.3    24.1—————\nMX17004    20102    tmin—    14.4    14.4—————\nMX17004    20103    tmax————    32.1———\nMX17004    20103    tmin————    14.2———\nMX17004    20104    tmax————————\nMX17004    20104    tmin————————\nMX17004    20105    tmax————————\nMX17004    20105    tmin————————\nTable 11:  Original weather dataset.  There is a column for each possible day in the month.\nColumns d9 to d31 have been omitted to conserve space.\niddateelement    value\nMX17004    2010-01-30    tmax27.8\nMX17004    2010-01-30    tmin14.5\nMX17004    2010-02-02    tmax27.3\nMX17004    2010-02-02    tmin14.4\nMX17004    2010-02-03    tmax24.1\nMX17004    2010-02-03    tmin14.4\nMX17004    2010-02-11    tmax29.7\nMX17004    2010-02-11    tmin13.4\nMX17004    2010-02-23    tmax29.9\nMX17004    2010-02-23    tmin10.7\n(a) Molten data\niddatetmax    tmin\nMX17004    2010-01-3027.814.5\nMX17004    2010-02-0227.314.4\nMX17004    2010-02-0324.114.4\nMX17004    2010-02-1129.713.4\nMX17004    2010-02-2329.910.7\nMX17004    2010-03-0532.114.2\nMX17004    2010-03-1034.516.8\nMX17004    2010-03-1631.117.6\nMX17004    2010-04-2736.316.7\nMX17004    2010-05-2733.218.2\n(b) Tidy data\nTable 12:  (a) Molten weather dataset.  This is almost tidy, but instead of values, theelement\ncolumn contains names of variables.  Missing values are dropped to conserve space.  (b) Tidy","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":10,"lines":{"from":1,"to":40}}}}],["21",{"pageContent":"Table 12:  (a) Molten weather dataset.  This is almost tidy, but instead of values, theelement\ncolumn contains names of variables.  Missing values are dropped to conserve space.  (b) Tidy\nweather dataset. Each row represents the meteorological measurements for a single day. There\nare two measured variables,  minimum (tmin) and maximum (tmax) temperature;  all other\nvariables are fixed.\nmissing values, making them implicit rather than explicit. This is permissible because we know\nhow many days are in each month and can easily reconstruct the explicit missing values.\nThis dataset is mostly tidy, but we have two variables stored in rows:tminandtmax, the\ntype of observation.  Not shown in this example are the other meteorological variablesprcp\n(precipitation) andsnow(snowfall).  Fixing the issue with the type of observation requires\nthe cast, or unstack, operation.  This performs the inverse of melting by rotating theelement\nvariable back out into the columns (Table 12(b)).  This form is tidy.  There is one variable in\neach column, and each row represents a day’s observations.  The cast operation is described\nin depth in Wickham (2007).","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":10,"lines":{"from":39,"to":52}}}}],["22",{"pageContent":"Journal of Statistical Software11\nid    artisttracktime\n1    2 PacBaby Don’t Cry4:22\n2    2Ge+herThe Hardest Part Of ...3:15\n3    3 Doors DownKryptonite3:53\n4    3 Doors DownLoser4:24\n5    504 BoyzWobble Wobble3:35\n6    98^0Give Me Just One Nig...    3:24\n7    A*TeensDancing Queen3:44\n8    AaliyahI Don’t Wanna4:15\n9    AaliyahTry Again4:03\n10    Adams, YolandaOpen My Heart5:30\n11    Adkins, TraceMore3:05\n12    Aguilera, Christina    Come On Over Baby3:38\n13    Aguilera, Christina    I Turn To You4:00\n14    Aguilera, Christina    What A Girl Wants3:18\n15    Alice DeejayBetter Off Alone6:50\nid    daterank\n1    2000-02-2687\n1    2000-03-0482\n1    2000-03-1172\n1    2000-03-1877\n1    2000-03-2587\n1    2000-04-0194\n1    2000-04-0899\n2    2000-09-0291\n2    2000-09-0987\n2    2000-09-1692\n3    2000-04-0881\n3    2000-04-1570\n3    2000-04-2268\n3    2000-04-2967\n3    2000-05-0666\nTable  13:  Normalized  Billboard  dataset  split  up  into  song  dataset  (left)  and  rank  dataset\n(right).  First 15 rows of each dataset shown;genreomitted from song dataset,weekomitted\nfrom rank dataset.\n3.4.  Multiple types in one table\nDatasets often involve values collected at multiple levels, on different types of observational\nunits.  During tidying, each type of observational unit should be stored in its own table.  This\nis closely related to the idea of database normalization, where each fact is expressed in only\none place.  If this is not done, it is possible for inconsistencies to occur.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":11,"lines":{"from":1,"to":41}}}}],["23",{"pageContent":"is closely related to the idea of database normalization, where each fact is expressed in only\none place.  If this is not done, it is possible for inconsistencies to occur.\nThe  Billboard  dataset  described  in  Table  8  actually  contains  observations  on  two  types  of\nobservational units:  the song and its rank in each week.  This manifests itself through the\nduplication of facts about the song:artistandtimeare repeated for every song in each\nweek.   The  Billboard  dataset  needs  to  be  broken  down  into  two  datasets:  a  song  dataset\nwhich storesartist,song nameandtime,  and a ranking dataset which gives therankof\nthesongin eachweek.  Table 13 shows these two datasets.  You could also imagine a week\ndataset which would record background information about the week, maybe the total number\nof songs sold or similar demographic information.\nNormalization is useful for tidying and eliminating inconsistencies.  However, there are few\ndata analysis tools that work directly with relational data, so analysis usually also requires\ndenormalization or merging the datasets back into one table.\n3.5.  One type in multiple tables\nIt is also common to find data values about a single type of observational unit spread out\nover multiple tables or files.  These tables and files are often split up by another variable, so\nthat each represents a single year, person, or location.  As long as the format for individual\nrecords is consistent, this is an easy problem to fix:","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":11,"lines":{"from":40,"to":57}}}}],["24",{"pageContent":"that each represents a single year, person, or location.  As long as the format for individual\nrecords is consistent, this is an easy problem to fix:\n1.  Read the files into a list of tables.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":11,"lines":{"from":56,"to":58}}}}],["25",{"pageContent":"12Tidy Data\n2.  For each table, add a new column that records the original file name (because the file\nname is often the value of an important variable).\n3.  Combine all tables into a single table.\nTheplyrpackage  makes  this  a  straightforward  task  inR.  The  following  code  generates  a\nvector of file names in a directory (data/) which match a regular expression (ends in.csv).\nNext we name each element of the vector with the name of the file.  We do this becauseplyr\nwill preserve the names in the following step, ensuring that each row in the final data frame\nis labeled with its source.  Finally,ldply()loops over each path, reading in the CSV file and\ncombining the results into a single data frame.\nR> paths <- dir(\"data\", pattern = \"\\\\.csv$\", full.names = TRUE)\nR> names(paths) <- basename(paths)\nR> ldply(paths, read.csv, stringsAsFactors = FALSE)\nOnce you have a single table, you can perform additional tidying as needed.  An example of\nthis type of cleaning can be found athttps://github.com/hadley/data-baby-nameswhich\ntakes 129 yearly baby name tables provided by the US Social Security Administration and\ncombines them into a single file.\nA  more  complicated  situation  occurs  when  the  dataset  structure  changes  over  time.   For\nexample, the datasets may contain different variables, the same variables with different names,\ndifferent file formats, or different conventions for missing values.  This may require you to tidy","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":12,"lines":{"from":1,"to":20}}}}],["26",{"pageContent":"example, the datasets may contain different variables, the same variables with different names,\ndifferent file formats, or different conventions for missing values.  This may require you to tidy\neach  file  individually  (or,  if  you  are  lucky,  in  small  groups)  and  then  combine  them  once\ntidied.   An  example  of  this  type  of  tidying  is  illustrated  inhttps://github.com/hadley/\ndata-fuel-economy, which shows the tidying of EPA fuel economy data for over 50,000 cars\nfrom 1978 to 2008.  The raw data is available online, but each year is stored in a separate file\nand there are four major formats with many minor variations, making tidying this dataset a\nconsiderable challenge.\n4.  Tidy tools\nOnce you have a tidy dataset, what can you do with it?  Tidy data is only worthwhile if it\nmakes analysis easier.  This section discusses tidy tools, tools that take tidy datasets as input\nand  return  tidy  datasets  as  output.   Tidy  tools  are  useful  because  the  output  of  one  tool\ncan be used as the input to another.  This allows you to simply and easily compose multiple\ntools  to  solve  a  problem.   Tidy  data  also  ensures  that  variables  are  stored  in  a  consistent,\nexplicit manner.  This makes each tool simpler, because it does not need a Swiss Army knife\nof parameters for dealing with different dataset structures.\nTools can be messy for two reasons:  either they take messy datasets as input (messy-input","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":12,"lines":{"from":19,"to":35}}}}],["27",{"pageContent":"of parameters for dealing with different dataset structures.\nTools can be messy for two reasons:  either they take messy datasets as input (messy-input\ntools) or they produce messy datasets as output (messy-output tools).  Messy-input tools are\ntypically more complicated than tidy-input tools because they need to include some parts of\nthe tidying process.  This can be useful for common types of messy datasets, but it typically\nmakes the function more complex, harder to use and harder to maintain.  Messy-output tools\nare frustrating and slow down analysis because they cannot be easily composed and you must\nconstantly think about how to convert from one format to another.  We will see examples of\nboth in the following sections.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":12,"lines":{"from":34,"to":42}}}}],["28",{"pageContent":"Journal of Statistical Software13\nNext, I give examples of tidy and messy tools for three important components of analysis: data\nmanipulation, visualization and modeling.  I will focus particularly on tools provided byR,\nbecause it has many existing tidy tools, but I will also touch on other statistical programming\nenvironments, such asSAS(SASInstitute Inc. 2013),SPSS(IBM Corporation 2013) andStata\n(StataCorp. 2013).\n4.1.  Manipulation\nData manipulation includes variable-by-variable transformation (e.g.,logorsqrt), as well as\naggregation, filtering and reordering.  In my experience, these are the four fundamental verbs\nof data manipulation:\nFilter:  subsetting or removing observations based on some condition.\nTransform:  adding  or  modifying  variables.   These  modifications  can  involve  either  a\nsingle variable (e.g., log-transformation), or multiple variables (e.g., computing density\nfrom weight and volume).\nAggregate:  collapsing multiple values into a single value (e.g.,  by summing or taking\nmeans).\nSort:  changing the order of observations.\nAll these operations are made easier when there is a consistent way to refer to variables.  Tidy\ndata provides this because each variable resides in its own column.\nInR, filtering is performed by the baseRfunctionsubset()and transforming by the baseR\nfunctiontransform(). These are input and output-tidy.  Theaggregate()function performs","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":13,"lines":{"from":1,"to":21}}}}],["29",{"pageContent":"InR, filtering is performed by the baseRfunctionsubset()and transforming by the baseR\nfunctiontransform(). These are input and output-tidy.  Theaggregate()function performs\ngroup-wise aggregation.  It is input-tidy.  Provided that a single aggregation method is used,\nit is also output-tidy.  Theplyrpackage provides tidysummarise()andarrange()functions\nfor aggregation and sorting.\nThe four verbs can be, and often are, modified by the “by” preposition.  We often need group-\nwise aggregates, transformations and subsets, to pick the biggest in each group, to average\nover replicates and so on.  Combining each of the four verbs with a by operator allows them\nto  operate on subsets of a  data  frame at a  time.  MostSASPROCs possess aBYstatement\nwhich allows the operation to be performed by group, and are generally input-tidy.  BaseR\npossesses aby()function, which is input-tidy, but not output-tidy, because it produces a list.\nTheddply()function from theplyrpackage is a tidy alternative.\nOther tools are needed when we have multiple datasets.  An advantage of tidy data is the ease\nwith which it can be combined with other tidy datasets.  All that is needed is a join operator\nthat works by matching common variables and adding new columns.  This is implemented in\nthemerge()function in baseR, or thejoin()function inplyr.  Compare these operators with\nthe difficulty of combining datasets stored in arrays.  This task typically requires painstaking","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":13,"lines":{"from":20,"to":36}}}}],["30",{"pageContent":"themerge()function in baseR, or thejoin()function inplyr.  Compare these operators with\nthe difficulty of combining datasets stored in arrays.  This task typically requires painstaking\nalignment  before  matrix  operations  can  be  used,  which  can  can  make  errors  very  hard  to\ndetect.\n4.2.  Visualization\nTidy visualization tools only need to be input-tidy as their output is visual.  Domain specific","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":13,"lines":{"from":35,"to":40}}}}],["31",{"pageContent":"14Tidy Data\nlanguages work particularly well for the visualization of tidy datasets because they can de-\nscribe a visualization as a mapping between variables and aesthetic properties of the graph\n(e.g.,  position,  size,  shape  and  color).   This  is  the  idea  behind  the  grammar  of  graphics\n(Wilkinson 2005), and the layered grammar of graphics (Wickham 2010), an extension tai-\nlored specifically forR.\nMost  graphical  tools  inRare  input-tidy,  including  thebaseplot()function,  thelattice\nfamily of plots (Sarkar 2008) andggplot2(Wickham 2009).  Some specialized tools exist for\nvisualizing messy datasets.  Some baseRfunctions likebarplot(),matplot(),dotchart(),\nandmosaicplot(), work with messy datasets where variables are spread out over multiple\ncolumns.  Similarly, the parallel coordinates plot (Wegman 1990; Inselberg 1985) can be used\nto create time series plots for messy datasets where each time point is a column.\n4.3.  Modeling\nModeling is the driving inspiration of this work because most modeling tools work best with\ntidy  datasets.   Every  statistical  language  has  a  way  of  describing  a  model  as  a  connection\namong different variables, a domain specific language that connects responses to predictors:\nR(lm()):y ~ a + b + c * d.\nSAS(PROC GLM):y = a + b + c + d + c * d.\nSPSS(glm):y BY a b c d / DESIGN a b c d c * d.\nStata(regress):y a b c#d.\nThis  is  not  to  say  that  tidy  data  is  the  format  used  internally  to  compute  the  regression.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":14,"lines":{"from":1,"to":21}}}}],["32",{"pageContent":"SPSS(glm):y BY a b c d / DESIGN a b c d c * d.\nStata(regress):y a b c#d.\nThis  is  not  to  say  that  tidy  data  is  the  format  used  internally  to  compute  the  regression.\nSignificant  transformations  take  place  to  produce  a  numeric  matrix  that  can  easily  be  fed\nto  standard  linear  algebra  routines.   Common  transformations  include  adding  an  intercept\ncolumn (a column of ones), turning categorical variables into multiple binary dummy variables,\nand projecting data onto the appropriate basis of a spline function.\nThere  have  been  some  attempts  to  adapt  modeling  functions  for  specific  types  of  messy\ndatasets.   For  example,  inSAS’sPROC GLM,  multiple  variables  on  the  response  side  of  the\nequation will be interpreted as repeated measures if theREPEATEDkeyword is present.  For\nthe raw Billboard data, we could construct a model of the formwk1 - xwk76 = trackinstead\nofrank = week * trackon the tidy data.\nAnother interesting example is the classic pairedttest, which can be computed in two ways\ndepending on how the data is stored.  If the data is stored as in Table 14(a), then a paired\nttest is just attest applied to the mean difference betweenxandy.  If it is stored in the form\nof Table 14(b), then an equivalent result can be produced by fitting a mixed effects model,\nwith a fixed dummy variable representing thevariable, and a random intercept for each id.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":14,"lines":{"from":19,"to":35}}}}],["33",{"pageContent":"of Table 14(b), then an equivalent result can be produced by fitting a mixed effects model,\nwith a fixed dummy variable representing thevariable, and a random intercept for each id.\nInR’slme4(Bates, Maechler, Bolker, and Walker 2014) notation, this is expressed asvalue\n~ variable + (1 | id).  Either way of modeling the data yields the same result.  Without\nmore information we cannot say which form of the data is tidy:  ifxandyrepresent length\nof left and right arms, then Table 14(a) is tidy, ifxandyrepresent measurements on day 1\nand day 10, then Table 14(b) is tidy.\nWhile model inputs usually require tidy inputs, such attention to detail does not carry over\nto  model  outputs.   Outputs  such  as  predictions  and  estimated  coefficients  are  not  always","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":14,"lines":{"from":34,"to":42}}}}],["34",{"pageContent":"Journal of Statistical Software15\nidxy\n1    22.19    24.05\n2    19.82    22.91\n3    19.81    21.19\n4    17.49    18.59\n5    19.44    19.85\n(a) Data for pairedttest\nid    variablevalue\n1    x22.19\n2    x19.82\n3    x19.81\n4    x17.49\n5    x19.44\n1    y24.05\n2    y22.91\n3    y21.19\n4    y18.59\n5    y19.85\n(b)  Data  for  mixed  effects\nmodel\nTable 14:  Two data sets for performing the same test.\ntidy.   This  makes  it  more  difficult  to  combine  results  from  multiple  models.   For  example,\ninR, the default representation of model coefficients is not tidy because it does not have an\nexplicit variable that records the variable name for each estimate, they are instead recorded\nas row names.  InR, row names must be unique, so combining coefficients from many models\n(e.g., from bootstrap resamples, or subgroups) requires workarounds to avoid losing important\ninformation.  This knocks you out of the flow of analysis and makes it harder to combine the\nresults  from  multiple  models.   I  am  not  currently  aware  of  any  packages  that  resolve  this\nproblem.\n5.  Case study\nThe following case study illustrates how tidy data and tidy tools make data analysis easier\nby  easing  the  transitions  between  manipulation,  visualization  and  modeling.   You  will  not\nsee  any  code  that  exists  solely  to  get  the  output  of  one  function  into  the  right  format  to\ninput to another.  I will show theRcode that performs the analysis, but even if you are not","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":15,"lines":{"from":1,"to":35}}}}],["35",{"pageContent":"see  any  code  that  exists  solely  to  get  the  output  of  one  function  into  the  right  format  to\ninput to another.  I will show theRcode that performs the analysis, but even if you are not\nfamiliar withRor the exact idioms I use, I have tried to make it easy to understand by tightly\ninterleaving code, results and explanation.\nThe case study uses individual-level mortality data from Mexico.  The goal is to find causes\nof death with unusual temporal patterns within a day.  Figure 1 shows the temporal pattern,\nthe number of deaths per hour, for all causes of death.  My goal is to find the diseases that\ndiffer most from this pattern.\nThe  full  dataset  has  information  on  539,530  deaths  in  Mexico  in  2008  and  55  variables,\nincluding the location and time of death, the cause of death, and demographics of the deceased.\nTable 15 shows a small sample of the dataset, focusing on variables related to time of death\n(year,month,dayandhour), and cause of death (cod).\nTo achieve our goal of finding unusual temporal patterns, we do the following.  First, we count\nthe number of deaths in each hour (hod) for each cause (cod) with the tidycountfunction.\nR> hod2 <- count(deaths, c(\"hod\", \"cod\"))","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":15,"lines":{"from":34,"to":48}}}}],["36",{"pageContent":"16Tidy Data\n19,000\n20,000\n21,000\n22,000\n23,000\n24,000\n05101520\nHour of day\nNumber of deaths\nFigure 1:  Temporal pattern of all causes of death.\nyod    mod    dod    hod    cod\n2008111    B20\n2008124    I67\n2008138    I50\n20081412    I50\n20081516    K70\n20081618    I21\n20081720    I21\n200818—    K74\n20081105    K74\n20081119    I21\n200811215    I25\n200811320    R54\n20081152    I61\n20081167    I21\n200811713    I21\nTable 15:  A sample of 16 rows and 5 columns from the original dataset of 539,530 rows and\n55 columns.\nThen we remove missing (and hence uninformative for our purpose) values withsubset.\nR> hod2 <- subset(hod2, !is.na(hod))\nThis gives Table 16(a).  To provide informative labels for disease, we next join the dataset to\nthecodesdataset, connected by thecodvariable.  This adds a new variable,disease, shown\nin Table 16(b).\nR> hod2 <- join(hod2, codes, by = \"cod\")\nThe  total  deaths  for  each  cause  varies  over  several  orders  of  magnitude:  there  are  46,794\ndeaths from heart attack but only 10 from avalanche.  This means that rather than the total","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":16,"lines":{"from":1,"to":37}}}}],["37",{"pageContent":"Journal of Statistical Software17\nnumber, it makes more sense to compare the proportion of deaths in each hour.  We compute\nthis  by  breaking  the  dataset  down  bycod,  and  thentransform()ing  to  add  a  newprop\ncolumn, the hourly frequency divided by the total number of deaths from that cause.  This\nnew column is Table 16(c).\nddply()breaks down the first argument (hod2) by its second (thecodvariable), and then\napplies the third argument (transform) to each resulting piece.  The fourth argument (prop\n= freq / sum(freq)) is then passed on totransform().\nR> hod2 <- ddply(hod2, \"cod\", transform, prop = freq / sum(freq))\nWe then compute the overall average death rate for each hour, and merge that back into the\noriginal dataset.  This yields Table 16(d).  By comparingproptoprop_all,  we can easily\ncompare each disease with the overall incidence pattern.\nFirst, we work out the number of people dying each hour.  We break downhod2byhod, and\ncompute the total for each cause of death.\nR> overall <- ddply(hod2, \"hod\", summarise, freq_all = sum(freq))\nNext, we work out the overall proportion of people dying each hour.\nR> overall <- transform(overall, prop_all = freq_all / sum(freq_all))\nFinally, we join the overall dataset with the individual dataset to make it easier to compare\nthe two.\nR> hod2 <- join(hod2, overall, by = \"hod\")\nNext we compute a distance between the temporal pattern of each cause of death and the","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":17,"lines":{"from":1,"to":21}}}}],["38",{"pageContent":"the two.\nR> hod2 <- join(hod2, overall, by = \"hod\")\nNext we compute a distance between the temporal pattern of each cause of death and the\noverall temporal pattern.  There are many ways to measure this distance, but I found a simple\nmean squared deviation to be revealing.  We also record the sample size, the total number of\ndeaths from that cause.  To ensure that the diseases we consider are sufficiently representative\nwe will only work with diseases with more than 50 total deaths (∼2/hour).\nR> devi <- ddply(hod2, \"cod\", summarise, n = sum(freq),\n+    dist = mean((prop - prop_all)^2))\nR> devi <- subset(devi, n > 50)\nWe do not know the variance characteristics of this estimator, but we can explore it visually\nby plottingnvs.deviation, Figure 2(a).  On a linear scale, the plot shows little, except that\nvariability decreases with sample size.  But on the log-log scale, Figure 2(b), there is a clear\npattern.  This pattern is particularly easy to see when we add the line of best fit from a robust\nlinear model.\nR> ggplot(data = devi, aes(x = n, y = dist) + geom_point()\nR> last_plot() + scale_x_log10() + scale_y_log10() +\n+    geom_smooth(method = \"rlm\", se = FALSE)","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":17,"lines":{"from":19,"to":36}}}}],["39",{"pageContent":"18Tidy Data\nhod    codfreq\n8    B164\n8    E843\n8    I212205\n8    N18315\n9    B167\n9    E841\n9    I212209\n9    N18333\n10    B1610\n10    E847\n10    I212434\n10    N18343\n11    B166\n11    E843\n11    I212128\n(a)\ndisease\nAcute hepatitis B\nCystic fibrosis\nAcute myocardial infarction\nChronic renal failure\nAcute hepatitis B\nCystic fibrosis\nAcute myocardial infarction\nChronic renal failure\nAcute hepatitis B\nCystic fibrosis\nAcute myocardial infarction\nChronic renal failure\nAcute hepatitis B\nCystic fibrosis\nAcute myocardial infarction\n(b)\nprop\n0.04\n0.03\n0.05\n0.04\n0.07\n0.01\n0.05\n0.04\n0.10\n0.07\n0.05\n0.04\n0.06\n0.03\n0.05\n(c)\nfreqall    propall\n219150.04\n219150.04\n219150.04\n219150.04\n224010.04\n224010.04\n224010.04\n224010.04\n243210.05\n243210.05\n243210.05\n243210.05\n238430.05\n238430.05\n238430.05\n(d)\nTable 16:  A sample of four diseases and four hours fromhod2data frame.\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":18,"lines":{"from":1,"to":389}}}}],["40",{"pageContent":"l\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\n0.000\n0.002\n0.004\n0.006\n010000200003000040000\nn\ndist\n(a) Linear scales\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\n0.001\n0.0001\n0.00001\n100100010000\nn\ndist\n(b) Log scales","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":18,"lines":{"from":290,"to":979}}}}],["41",{"pageContent":"l\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\n0.001\n0.0001\n0.00001\n100100010000\nn\ndist\n(b) Log scales\nFigure  2:  (a)  Plot  ofnvs.deviation.   Variability  ofdeviationis  dominated  by  sample\nsize:  small samples have large variability.  (b) Log-log plot makes it easy to see the pattern of\nvariation as well as unusually high values.  The blue line is a robust line of best fit.\nWe are interested in points that have highy-values, relative to theirx-neighbors.  Controlling\nfor the number of deaths, these points represent the diseases which depart the most from the\noverall pattern.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":18,"lines":{"from":901,"to":985}}}}],["42",{"pageContent":"Journal of Statistical Software19\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\nl\n−1\n0\n1\n2\n3\n100100010000\nn\nresid\nFigure 3:  Residuals from a robust linear model predicting log(dist) by log(n).  Horizontal line\nat 1.5 shows threshold for further exploration.\nTo find these unusual points, we fit a robust linear model and plot the residuals, Figure 3.  The\nplot shows an empty region around a residual of 1.5.  So somewhat arbitrarily, we will select\nthose diseases with a residual greater than 1.5.  We do this in two steps:  first, we select the\nappropriate rows fromdevi(one row per disease), and then we find the matching temporal","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":19,"lines":{"from":1,"to":462}}}}],["43",{"pageContent":"those diseases with a residual greater than 1.5.  We do this in two steps:  first, we select the\nappropriate rows fromdevi(one row per disease), and then we find the matching temporal\ncourse information from the original summary dataset (24 rows per disease).\nR> devi$resid <- resid(rlm(log(dist) ~ log(n), data = devi))\nR> unusual <- subset(devi, resid > 1.5)\nR> hod_unusual <- match_df(hod2, unusual)\nFinally, we plot the temporal course for each unusual cause, Figure 4.  We split the diseases\ninto  two  plots  because  of  differences  in  variability.   The  top  plot  shows  diseases  with  over\n350 deaths and the bottom with under 350.  The causes of death fall into three main groups:\nmurder, drowning, and transportation related.  Murder is more common at night, drowning\nin the afternoon,  and transportation related deaths during commute times.  The pale gray\nline in the background shows the temporal course across all diseases.\nR> ggplot(data = subset(hod_unusual, n > 350), aes(x = hod, y = prop)) +\n+    geom_line(aes(y = prop_all), data = overall, colour = \"grey50\") +\n+    geom_line() + facet_wrap(~ disease, ncol = 3)\n6.  Discussion\nData cleaning is an important problem, but it is an uncommon subject of study in statistics.\nThis paper carves out a small but important subset of data cleaning that I have called data\ntidying:  structuring datasets to facilitate manipulation,  visualization and modeling.  There","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":19,"lines":{"from":461,"to":479}}}}],["44",{"pageContent":"20Tidy Data\nAssault (homicide) by other\nand unspecified firearm\ndischarge\nAssault (homicide) by sharp\nobject\nDrowning and submersion while\nin natural water\nExposure to unspecified\nelectric current\nMotor− or nonmotor−vehicle\naccident, type of vehicle\nunspecified\nPedestrian injured in other\nand unspecified transport\naccidents\nTraffic accident of specified\ntype but victim's mode of\ntransport unknown\nUnspecified drowning and\nsubmersion\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0.000\n0.025\n0.050\n0.075\n0.100\n0.125\n0510152005101520\nhod\nprop\nAccident to powered aircraft\ncausing injury to occupant\nBus occupant injured in other\nand unspecified transport\naccidents\nOther specified drowning and\nsubmersion\nSudden infant death syndromeVictim of lightning\n0.0\n0.1\n0.2\n0.3\n0.0\n0.1\n0.2\n0.3\n0510152005101520\nhod\nprop\nFigure 4:  Causes of death with unusual temporal courses.  Overall hourly death rate shown\nin gray.  (Top) Causes of death with more than 350 deaths over a year.  (Bottom) Causes of\ndeath with fewer than 350 deaths.  Note that they-axes are on different scales.\nis still much work to be done.  Incremental improvements will happen as our understanding\nof tidy data and tidy tools improves, and as we improve our ability to reduce the friction of\ngetting data into a tidy form.\nBigger improvements may be possible by exploring alternative formulations of tidiness.  There","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":20,"lines":{"from":1,"to":68}}}}],["45",{"pageContent":"getting data into a tidy form.\nBigger improvements may be possible by exploring alternative formulations of tidiness.  There\nis a chicken-and-egg problem with tidy data:  if tidy data is only as useful as the tools that","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":20,"lines":{"from":67,"to":69}}}}],["46",{"pageContent":"Journal of Statistical Software21\nwork with it, then tidy tools will be inextricably linked to tidy data.  This makes it easy to\nget stuck in a local maximum where independently changing data structures or data tools\nwill not improve workflow.  Breaking out of this local maximum is hard.  It requires long-term\nconcerted  effort  with  the  prospect  of  many  false  starts.   While  I  hope  that  the  tidy  data\nframework is not one of those false starts, I also do not see it as the final solution.  I hope\nothers will build on this framework to develop even better data storage strategies and better\ntools.\nSurprisingly, I have found few principles to guide the design of tidy data, which acknowledge\nboth statistical and cognitive factors.  To date, my work has been driven by my experience\ndoing data analysis, my knowledge of relational database design, and my own rumination on\nthe tools of data analysis.  The human factors,  user-centered design,  and human-computer\ninteraction communities may be able to add to this conversation, but the design of data and\ntools to work with it has not been an active research topic in those fields.  In the future, I\nhope to use methodologies from these fields (user-testing, ethnography, talk-aloud protocols)\nto improve our understanding of the cognitive side of data analysis, and to further improve\nour ability to design appropriate tools.\nOther formulations of tidy data are possible.  For example, it would be possible to construct","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":21,"lines":{"from":1,"to":18}}}}],["47",{"pageContent":"our ability to design appropriate tools.\nOther formulations of tidy data are possible.  For example, it would be possible to construct\na set of tools for dealing with values stored in multidimensional arrays.  This is a common\nstorage format for large biomedical datasets generated by microarrays or fMRI’s.  It is also\nnecessary for many multivariate methods based on matrix manipulation. Fortunately, because\nthere  are  many  efficient  tools  for  working  with  high-dimensional  arrays,  even  sparse  ones,\nsuch an array-tidy format is not only likely to be quite compact and efficient, it should also\nbe  able  to  easily  connect  with  the  mathematical  basis  of  statistics.   This,  in  fact,  is  the\napproach  taken  by  thepandasPythondata  analysis  library  (McKinney  2010).   Even  more\ninterestingly, we could consider tidy tools that can ignore the underlying data representation\nand automatically choose between array-tidy and dataframe-tidy formats to optimize memory\nusage and performance.\nApart  from  tidying,  there  are  many  other  tasks  involved  in  cleaning  data:   parsing  dates\nand  numbers,  identifying  missing  values,  correcting  character  encodings  (for  international\ndata),  matching similar but not identical values (created by typos),  verifying experimental\ndesign, and filling in structural missing values, not to mention model-based data cleaning that\nidentifies suspicious values.  Can we develop other frameworks to make these tasks easier?","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":21,"lines":{"from":17,"to":33}}}}],["48",{"pageContent":"design, and filling in structural missing values, not to mention model-based data cleaning that\nidentifies suspicious values.  Can we develop other frameworks to make these tasks easier?\nAcknowledgments\nThis work would not be possible without the many conversations I have had about data and\nhow to deal with them statistically.  I would particularly like to thank Phil Dixon, Di Cook,\nand Heike Hofmann, who have put up with numerous questions over the years.  I would also\nlike to thank the users of thereshapepackage who have provided many challenging problems,\nand my students who continue to challenge me to explain what I know in a way that they\ncan understand.  I would also like to thank Bob Muenchen, Burt Gunter, Nick Horton and\nGarrett Grolemund who gave detailed comments on earlier drafts, and to particularly thank\nRoss Gayler who provided the nice example of the challenges of defining a variable and Ben\nBolker who showed me the natural equivalence between a pairedttest and a mixed effects\nmodel.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":21,"lines":{"from":32,"to":44}}}}],["49",{"pageContent":"22Tidy Data\nReferences\nBates D, Maechler M, Bolker B, Walker S (2014).lme4:  Linear Mixed-Effects Models Using\nEigenandS4.Rpackage  version  1.1-7,  URLhttp://CRAN.R-project.org/package=\nlme4.\nCodd EF (1990).The Relational Model for Database Management:  Version 2. Addison-Wesley\nLongman Publishing, Boston.\nDasu T, Johnson T (2003).Exploratory Data Mining and Data Cleaning. John Wiley & Sons.\nIBM Corporation (2013).IBMSPSSStatistics  22.  IBM Corporation,  Armonk,  NY.  URL\nhttp://www.ibm.com/software/analytics/spss/.\nInselberg  A  (1985).  “The  Plane  with  Parallel  Coordinates.”The  Visual  Computer,1(2),\n69–91.\nKandel S, Paepcke A, Hellerstein J, Heer J (2011). “Wrangler: Interactive Visual Specification\nof Data Transformation Scripts.” InACM Human Factors in Computing Systems (CHI).\nLakshmanan LVS, Sadri F, Subramanian IN (1996). “SchemaSQL– A Language for Interop-\nerability in Relational Multi-Database Systems.”  InProceedings  of  the  22th  International\nConference on Very Large Data Bases (VLDB’96), pp. 239–250.  ISSN 1047-7349.\nMcKinney W (2010).  “Data Structures for Statistical Computing inPython.”  In S van der\nWalt, J Millman (eds.),Proceedings of the 9thPythonin Science Conference, pp. 51–56.\nRaman V, Hellerstein JM (2001).  “Potter’s Wheel:  An Interactive Data Cleaning System.”\nInProceedings of the 27th International Conference on Very Large Data Bases (VLDB’01),\npp. 381–390.\nRCore Team (2014).R: A Language and Environment for Statistical Computing.RFounda-","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":22,"lines":{"from":1,"to":23}}}}],["50",{"pageContent":"InProceedings of the 27th International Conference on Very Large Data Bases (VLDB’01),\npp. 381–390.\nRCore Team (2014).R: A Language and Environment for Statistical Computing.RFounda-\ntion for Statistical Computing, Vienna, Austria.  URLhttp://www.R-project.org/.\nSarkar D (2008).lattice:  Multivariate Data Visualization withR. Springer-Verlag, New York.\nSASInstitute Inc (2013).TheSASSystem, Version 9.4.SASInstitute Inc., Cary, NC.  URL\nhttp://www.sas.com/.\nStataCorp (2013).StataData Analysis Statistical Software:  Release 12. StataCorp LP, College\nStation, TX.  URLhttp://www.stata.com/.\nWegman EJ (1990). “Hyperdimensional Data Analysis Using Parallel Coordinates.”Journal\nof the American Statistical Association,85(411), 664–675.\nWickham  H  (2007).   “Reshaping  Data  with  thereshapePackage.”Journal  of  Statistical\nSoftware,21(12), 1–20.  URLhttp://www.jstatsoft.org/v21/i12/.\nWickham  H  (2009).ggplot2:   Elegant  Graphics  for  Data  Analysis.   Springer-Verlag,  New\nYork.","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":22,"lines":{"from":21,"to":35}}}}],["51",{"pageContent":"Journal of Statistical Software23\nWickham  H  (2010).   “A  Layered  Grammar  of  Graphics.”Journal  of  Computational  and\nGraphical Statistics,19(1), 3–28.\nWickham  H  (2011).   “The  Split-Apply-Combine  Strategy  for  Data  Analysis.”Journal  of\nStatistical Software,40(1), 1–29.  URLhttp://www.jstatsoft.org/v40/i01/.\nWilkinson L (2005).The Grammar of Graphics.  2nd edition. Springer-Verlag, New York.\nAffiliation:\nHadley Wickham\nRStudio\nand\nRice University\nE-mail:h.wickham@gmail.com\nURL:http://had.co.nz/\nJournal of Statistical Softwarehttp://www.jstatsoft.org/\npublished by the American Statistical Associationhttp://www.amstat.org/\nVolume 59, Issue 10Submitted:2013-02-20\nAugust 2014Accepted:2014-05-09","metadata":{"source":"docs/tiny-data.pdf","pdf":{"version":"1.10.100","info":{"PDFFormatVersion":"1.5","IsAcroFormPresent":false,"IsXFAPresent":false,"Title":"Tidy Data","Author":"Hadley Wickham","Subject":"Journal of Statistical Software","Keywords":"data cleaning, data tidying, relational databases, R","Creator":"LaTeX with hyperref package","Producer":"pdfTeX-1.40.14","CreationDate":"D:20140812114829+02'00'","ModDate":"D:20140812114829+02'00'","Trapped":{"name":"False"}},"metadata":null,"totalPages":23},"loc":{"pageNumber":23,"lines":{"from":1,"to":17}}}}]]